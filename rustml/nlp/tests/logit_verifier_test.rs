//! Logit Comparison Verifier: Integration test comparing Rust forward pass logits
//! against reference logits generated by llama-cpp-python.
//!
//! Run with:
//!   GGUF_MODEL_PATH=/tmp/gemma3-gguf/google_gemma-3-1b-it-Q4_0.gguf \
//!     cargo test -p rustml-nlp --release --test logit_verifier_test -- --nocapture
//!
//! If GGUF_MODEL_PATH is unset, the test is skipped (not failed).
//!
//! Reference logits are pre-generated by:
//!   python3 scripts/generate_reference_logits.py --model /path/to/model.gguf
//!
//! Tolerance calibration (2026-02, post rms_norm contiguity fix):
//!   Q4_0 quantization + different matmul/accumulation order produces small
//!   divergence from llama.cpp. Observed max logit diff: 0.89, max stat rel_err: 0.019.

use rustml_core::Tensor;
use rustml_gguf::GGUFFile;
use rustml_nlp::{
    convert_tensors, gguf_config_to_model_config, LanguageModel, LlmModel,
    ModelConfig,
};
use rustml_tokenizer::{GgufTokenizer, Tokenizer};
use rustml_nn::KVCache;
use serde_json::Value;
use std::collections::HashSet;

/// Reference logits JSON, generated once and checked into the repo.
const REFERENCE_JSON: &str = include_str!("fixtures/gemma3_reference_logits.json");

// === Tolerance tiers ===
// Tier 1 (hard fail): Catastrophic divergence — model is fundamentally broken
// Tier 2 (tracked): Expected divergence from Q4 quantization differences
// These will be tightened as implementation improves.

/// Top-K overlap: reference top-20 tokens must have at least this many in our top-50.
/// Observed: all 20/20 on all prompts (2026-02 post-fix).
const MIN_TOP20_OVERLAP: usize = 18;

/// Logit absolute tolerance for value comparison.
/// Observed max diff: 0.89 on chat_template (2026-02 post-fix).
const LOGIT_ABS_TOLERANCE: f32 = 2.0;

/// Relative tolerance for logit statistics.
/// Observed max rel_err: 0.019 on chat_template std (2026-02 post-fix).
const STAT_RELATIVE_TOLERANCE: f64 = 0.05;

fn get_model_path() -> Option<String> {
    std::env::var("GGUF_MODEL_PATH").ok()
}

/// Load model following the gemma3_gguf.rs pipeline.
fn load_model(
    gguf_path: &str,
) -> Result<(LlmModel, GgufTokenizer, ModelConfig), Box<dyn std::error::Error>> {
    let gguf = GGUFFile::parse_header(gguf_path)?;
    let gguf_config = gguf.to_model_config()?;
    let config = gguf_config_to_model_config(&gguf_config)?;
    let tokenizer = GgufTokenizer::from_gguf(&gguf)?;

    let loaded_tensors = gguf.load_and_remap_gemma3(gguf_path, config.n_layers)?;
    let tensors = convert_tensors(loaded_tensors);
    let mut model = LlmModel::from_pretrained_gemma3(&config, tensors)?;

    let use_native_q4 = std::env::var("DISABLE_Q4_MATMUL").is_err();
    for layer in &mut model.layers {
        layer.set_native_q4_matmul(use_native_q4);
    }

    Ok((model, tokenizer, config))
}

/// Extract logits for the last token position from model output.
/// Model output shape: [1, seq_len, vocab_size]
fn extract_last_logits(logits: &Tensor, seq_len: usize) -> Vec<f32> {
    let last_slice = logits
        .slice(1, seq_len - 1, seq_len)
        .expect("Failed to slice last position logits");
    last_slice.iter().collect()
}

/// Get top-k token IDs sorted by logit value (descending).
fn top_k_tokens(logits: &[f32], k: usize) -> Vec<(u32, f32)> {
    let mut indexed: Vec<(u32, f32)> = logits
        .iter()
        .enumerate()
        .map(|(i, &v)| (i as u32, v))
        .collect();
    indexed.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
    indexed.truncate(k);
    indexed
}

fn logit_stats(logits: &[f32]) -> (f64, f64, f64, f64) {
    let n = logits.len() as f64;
    let mean = logits.iter().map(|&x| x as f64).sum::<f64>() / n;
    let variance = logits
        .iter()
        .map(|&x| ((x as f64) - mean).powi(2))
        .sum::<f64>()
        / n;
    let std = variance.sqrt();
    let min = logits.iter().cloned().fold(f32::INFINITY, f32::min) as f64;
    let max = logits.iter().cloned().fold(f32::NEG_INFINITY, f32::max) as f64;
    (mean, std, min, max)
}

#[test]
fn verify_logits_match_reference() {
    let gguf_path = match get_model_path() {
        Some(path) => path,
        None => {
            eprintln!(
                "SKIP: Set GGUF_MODEL_PATH to run logit verification.\n\
                 Example:\n  \
                 GGUF_MODEL_PATH=/tmp/gemma3-gguf/google_gemma-3-1b-it-Q4_0.gguf \\\n  \
                 cargo test -p rustml-nlp --release --test logit_verifier_test -- --nocapture"
            );
            return;
        }
    };

    println!("\n=== Logit Comparison Verifier ===");
    println!("  Model: {}", gguf_path);

    // Parse reference data
    let reference: Value =
        serde_json::from_str(REFERENCE_JSON).expect("Failed to parse reference JSON");
    let prompts = reference["prompts"]
        .as_array()
        .expect("Missing prompts array");
    println!(
        "  Reference: {} prompts, generator={}",
        prompts.len(),
        reference["generator"]
    );

    // Load model
    println!("  Loading model...");
    let (model, tokenizer, config) = load_model(&gguf_path).expect("Failed to load model");
    let head_dim = config.head_dim.unwrap_or(config.dim / config.n_heads);
    let n_kv_heads = config.n_kv_heads.unwrap_or(config.n_heads);
    println!("  Model loaded.\n");

    let mut hard_failures: Vec<String> = Vec::new();
    let mut soft_issues: Vec<String> = Vec::new();

    for prompt_data in prompts {
        let name = prompt_data["name"].as_str().unwrap();
        let prompt_text = prompt_data["prompt"].as_str().unwrap();
        let ref_token_ids: Vec<u32> = prompt_data["token_ids"]
            .as_array()
            .unwrap()
            .iter()
            .map(|v| v.as_u64().unwrap() as u32)
            .collect();

        println!("--- Prompt: {} ---", name);
        println!("  Text: {:?}", prompt_text);
        println!(
            "  Reference token IDs ({}): {:?}",
            ref_token_ids.len(),
            &ref_token_ids
        );

        // Tokenize with our tokenizer to compare.
        // If the prompt starts with literal "<bos>", tokenizer now recognizes it as
        // CONTROL token ID 2 — so skip the manual BOS prepend to avoid a duplicate.
        let bos_id = 2u32; // Gemma BOS
        let encoded = tokenizer.encode(prompt_text).expect("Tokenization failed");
        let our_token_ids = if encoded.first() == Some(&bos_id) {
            encoded
        } else {
            let mut ids = vec![bos_id];
            ids.extend(encoded);
            ids
        };

        if our_token_ids != ref_token_ids {
            println!(
                "  WARN: Token ID mismatch (ours={}, ref={}). Using reference IDs for forward pass.",
                our_token_ids.len(),
                ref_token_ids.len()
            );
        } else {
            println!("  Token IDs match.");
        }

        // Use reference token IDs for forward pass to ensure we compare the same computation
        let input_ids = &ref_token_ids;
        let seq_len = input_ids.len();

        let input_data: Vec<f32> = input_ids.iter().map(|&id| id as f32).collect();
        let input = Tensor::from_vec(input_data, vec![1, seq_len])
            .expect("Failed to create input tensor");

        // Use forward_with_cache to match the gemma3_gguf.rs pipeline.
        // Note: for a single prefill (start_pos=0), forward() and forward_with_cache()
        // produce identical results — both pass offset 0 to RoPE.
        let mut cache = KVCache::new(config.n_layers, config.max_seq_len, head_dim, n_kv_heads);
        println!("  Running forward pass ({} tokens)...", seq_len);
        let logits_tensor = model
            .forward_with_cache(&input, &mut cache)
            .expect("Forward pass failed");
        let our_logits = extract_last_logits(&logits_tensor, seq_len);
        println!("  Got {} logits for last position.", our_logits.len());

        // Sanity check: logits should not be NaN or all zeros
        let has_nan = our_logits.iter().any(|x| x.is_nan());
        let all_zero = our_logits.iter().all(|&x| x == 0.0);
        if has_nan {
            hard_failures.push(format!("{}: logits contain NaN", name));
            println!("  [HARD FAIL] Logits contain NaN!");
            continue;
        }
        if all_zero {
            hard_failures.push(format!("{}: all logits are zero", name));
            println!("  [HARD FAIL] All logits are zero!");
            continue;
        }

        // Reference logit data
        let ref_logit_data = &prompt_data["last_position_logits"];
        let ref_top_logits: Vec<(u32, f64)> = ref_logit_data["top_logits"]
            .as_array()
            .unwrap()
            .iter()
            .map(|entry| {
                let tid = entry["token_id"].as_u64().unwrap() as u32;
                let val = entry["logit"].as_f64().unwrap();
                (tid, val)
            })
            .collect();
        let ref_stats = &ref_logit_data["stats"];

        // === Check 1: Top-1 token ID ===
        let our_top = top_k_tokens(&our_logits, 50);
        let our_top1 = our_top[0].0;
        let ref_top1 = ref_top_logits[0].0;

        let top1_token = tokenizer.decode(&[our_top1]).unwrap_or_default();
        let ref_top1_token = tokenizer.decode(&[ref_top1]).unwrap_or_default();

        if our_top1 == ref_top1 {
            println!(
                "  [PASS] Top-1 match: id={} {:?}",
                our_top1,
                top1_token.trim()
            );
        } else {
            println!(
                "  [SOFT] Top-1 mismatch: ours=id={} {:?}, ref=id={} {:?}",
                our_top1,
                top1_token.trim(),
                ref_top1,
                ref_top1_token.trim(),
            );
            soft_issues.push(format!("{}: top-1 mismatch (ours={}, ref={})", name, our_top1, ref_top1));
        }

        // === Check 2: Top-5 token ID set overlap ===
        let our_top5_set: HashSet<u32> = our_top.iter().take(5).map(|&(id, _)| id).collect();
        let ref_top5_set: HashSet<u32> =
            ref_top_logits.iter().take(5).map(|&(id, _)| id).collect();

        let top5_overlap = our_top5_set.intersection(&ref_top5_set).count();
        if our_top5_set == ref_top5_set {
            println!("  [PASS] Top-5 set match: {:?}", our_top5_set);
        } else {
            println!(
                "  [SOFT] Top-5 overlap: {}/5 common. Ours: {:?}, Ref: {:?}",
                top5_overlap, our_top5_set, ref_top5_set
            );
            soft_issues.push(format!("{}: top-5 overlap {}/5", name, top5_overlap));
        }

        // === Check 3: Top-20 overlap in our top-50 (hard fail if too low) ===
        let our_top50_set: HashSet<u32> = our_top.iter().take(50).map(|&(id, _)| id).collect();
        let ref_top20_set: HashSet<u32> =
            ref_top_logits.iter().take(20).map(|&(id, _)| id).collect();
        let top20_in_top50 = ref_top20_set.intersection(&our_top50_set).count();

        if top20_in_top50 >= MIN_TOP20_OVERLAP {
            println!(
                "  [PASS] Top-20 overlap: {}/20 ref tokens found in our top-50",
                top20_in_top50
            );
        } else {
            println!(
                "  [HARD FAIL] Top-20 overlap too low: {}/20 (need >= {})",
                top20_in_top50, MIN_TOP20_OVERLAP
            );
            hard_failures.push(format!(
                "{}: top-20 overlap {}/20 < {}",
                name, top20_in_top50, MIN_TOP20_OVERLAP
            ));
        }

        // === Check 4: Top-20 logit value comparison (informational + hard fail on catastrophic) ===
        println!("  Top-20 logit comparison:");
        let mut total_abs_diff = 0.0f64;
        let mut max_abs_diff = 0.0f64;
        let compare_count = ref_top_logits.len().min(20);
        for i in 0..compare_count {
            let ref_id = ref_top_logits[i].0;
            let ref_val = ref_top_logits[i].1 as f32;
            let our_val = if (ref_id as usize) < our_logits.len() {
                our_logits[ref_id as usize]
            } else {
                f32::NEG_INFINITY
            };
            let diff = (our_val - ref_val).abs();
            total_abs_diff += diff as f64;
            if diff as f64 > max_abs_diff {
                max_abs_diff = diff as f64;
            }
            let status = if diff <= LOGIT_ABS_TOLERANCE {
                "ok"
            } else {
                "DIFF"
            };
            if i < 5 || diff > LOGIT_ABS_TOLERANCE {
                let tok = tokenizer.decode(&[ref_id]).unwrap_or_default();
                println!(
                    "    [{:>4}] id={:<6} ref={:>8.3} ours={:>8.3} diff={:>6.3}  {:?}",
                    status,
                    ref_id,
                    ref_val,
                    our_val,
                    diff,
                    tok.trim()
                );
            }
        }
        let mean_abs_diff = total_abs_diff / compare_count as f64;
        println!(
            "  Logit diff summary: mean={:.3}, max={:.3}",
            mean_abs_diff, max_abs_diff
        );

        let logit_failures = (0..compare_count)
            .filter(|&i| {
                let ref_id = ref_top_logits[i].0;
                let ref_val = ref_top_logits[i].1 as f32;
                let our_val = if (ref_id as usize) < our_logits.len() {
                    our_logits[ref_id as usize]
                } else {
                    f32::NEG_INFINITY
                };
                (our_val - ref_val).abs() > LOGIT_ABS_TOLERANCE
            })
            .count();
        if logit_failures > 0 {
            hard_failures.push(format!(
                "{}: {}/{} logit values exceed tolerance {}",
                name, logit_failures, compare_count, LOGIT_ABS_TOLERANCE
            ));
        }

        // === Check 5: Logit statistics ===
        let (our_mean, our_std, our_min, our_max) = logit_stats(&our_logits);
        let ref_mean = ref_stats["mean"].as_f64().unwrap();
        let ref_std = ref_stats["std"].as_f64().unwrap();
        let ref_min = ref_stats["min"].as_f64().unwrap();
        let ref_max = ref_stats["max"].as_f64().unwrap();

        println!("  Logit stats comparison:");
        let mut stat_soft_failures = Vec::new();
        for (label, ours, reference) in [
            ("mean", our_mean, ref_mean),
            ("std", our_std, ref_std),
            ("min", our_min, ref_min),
            ("max", our_max, ref_max),
        ] {
            let rel_err = if reference.abs() > 1e-6 {
                ((ours - reference) / reference).abs()
            } else {
                (ours - reference).abs()
            };
            let status = if rel_err <= STAT_RELATIVE_TOLERANCE {
                "PASS"
            } else {
                "SOFT"
            };
            println!(
                "    [{}] {:>4}: ref={:>10.4} ours={:>10.4} rel_err={:.4}",
                status, label, reference, ours, rel_err
            );
            if rel_err > STAT_RELATIVE_TOLERANCE {
                stat_soft_failures.push(format!("{}(rel_err={:.4})", label, rel_err));
            }
        }
        if !stat_soft_failures.is_empty() {
            soft_issues.push(format!("{}: stat divergence: {}", name, stat_soft_failures.join(", ")));
        }

        println!();
    }

    // Summary
    println!("=== Summary ===");
    println!("  Hard failures: {}", hard_failures.len());
    println!("  Soft issues (tracked): {}", soft_issues.len());

    if !soft_issues.is_empty() {
        println!("\n  Tracked divergences (tighten tolerances as implementation improves):");
        for s in &soft_issues {
            println!("    - {}", s);
        }
    }

    if !hard_failures.is_empty() {
        println!("\n  Hard failures:");
        for f in &hard_failures {
            println!("    - {}", f);
        }
    }

    assert!(
        hard_failures.is_empty(),
        "Logit verification hard failure: {} issue(s):\n{}",
        hard_failures.len(),
        hard_failures.join("\n")
    );

    println!("\n  Test PASSED (with {} tracked divergences from llama.cpp reference).", soft_issues.len());
}
